{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nos.chdir(\"/kaggle/input/\")\n# os.mkdir('/kaggle/input/slim_trained')\nfor dirname, _, filenames in os.walk('../input/siim-covid19-detectionut'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-21T01:38:42.922455Z","iopub.execute_input":"2021-07-21T01:38:42.92305Z","iopub.status.idle":"2021-07-21T01:38:42.935638Z","shell.execute_reply.started":"2021-07-21T01:38:42.922956Z","shell.execute_reply":"2021-07-21T01:38:42.934429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_image = pd.read_csv(r'../input/siim-covid19-detection/train_image_level.csv')\ndata_study  = pd.read_csv(r'../input/siim-covid19-detection/train_study_level.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:38:51.088322Z","iopub.execute_input":"2021-07-21T01:38:51.088925Z","iopub.status.idle":"2021-07-21T01:38:51.246192Z","shell.execute_reply.started":"2021-07-21T01:38:51.088872Z","shell.execute_reply":"2021-07-21T01:38:51.245365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Concatinate the above files by ID's","metadata":{}},{"cell_type":"markdown","source":"Step1: Get the Path for the images","metadata":{}},{"cell_type":"code","source":"trainimlist = []\n\nfor dirname, _, filenames in os.walk('../input/siim-covid19-detection/train'):\n    for filename in filenames:\n        trainimlist.append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:38:56.016037Z","iopub.execute_input":"2021-07-21T01:38:56.016619Z","iopub.status.idle":"2021-07-21T01:39:19.55359Z","shell.execute_reply.started":"2021-07-21T01:38:56.016584Z","shell.execute_reply":"2021-07-21T01:39:19.552753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Step2: check image_id and train/Id's are the same","metadata":{}},{"cell_type":"code","source":"# check id in train_imgage_level and Names in the train folder are the same\n\n# to store path with order by id in train_imgage_level\n\nPath = [] \n\nfor image_id in data_image['id']:\n    target = image_id.replace('_image', '')\n    for path in trainimlist:\n        if target in path: \n            Path.append(path)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:39:22.97469Z","iopub.execute_input":"2021-07-21T01:39:22.976751Z","iopub.status.idle":"2021-07-21T01:39:31.090239Z","shell.execute_reply.started":"2021-07-21T01:39:22.976713Z","shell.execute_reply":"2021-07-21T01:39:31.089235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding the Path list to the data_image file","metadata":{}},{"cell_type":"code","source":"data_image[\"Path\"] = pd.Series(Path, index=data_image.index)\n\n# data_image id (6334) and images in train folder (6334) are one-to-one relationships\nlen(data_image['Path'].unique().tolist())","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:39:36.20459Z","iopub.execute_input":"2021-07-21T01:39:36.204979Z","iopub.status.idle":"2021-07-21T01:39:36.22368Z","shell.execute_reply.started":"2021-07-21T01:39:36.204942Z","shell.execute_reply":"2021-07-21T01:39:36.222673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking \ndata_image.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:39:42.113016Z","iopub.execute_input":"2021-07-21T01:39:42.11341Z","iopub.status.idle":"2021-07-21T01:39:42.13359Z","shell.execute_reply.started":"2021-07-21T01:39:42.113376Z","shell.execute_reply":"2021-07-21T01:39:42.13259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for itr in data_study['id']:\n    data_study['id'] = data_study['id'].str.replace('_study', '')","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:39:47.095787Z","iopub.execute_input":"2021-07-21T01:39:47.096214Z","iopub.status.idle":"2021-07-21T01:40:20.236065Z","shell.execute_reply.started":"2021-07-21T01:39:47.096176Z","shell.execute_reply":"2021-07-21T01:40:20.235249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"StudyInstanceID and data_study['id'] are related.\nSo, removing _study from data_study for merge the 2 data-frames.","metadata":{}},{"cell_type":"code","source":"data_study = data_study.rename(columns={'id': \"StudyInstanceUID\"})","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:40:24.217375Z","iopub.execute_input":"2021-07-21T01:40:24.21773Z","iopub.status.idle":"2021-07-21T01:40:24.223094Z","shell.execute_reply.started":"2021-07-21T01:40:24.217699Z","shell.execute_reply":"2021-07-21T01:40:24.222017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This step is for merge as merge requires the same column name","metadata":{}},{"cell_type":"code","source":"train = pd.merge(data_image, data_study, on='StudyInstanceUID')","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:40:39.698083Z","iopub.execute_input":"2021-07-21T01:40:39.6987Z","iopub.status.idle":"2021-07-21T01:40:39.719876Z","shell.execute_reply.started":"2021-07-21T01:40:39.698664Z","shell.execute_reply":"2021-07-21T01:40:39.718921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only rows are kept for which common keys are found in both data frames.\nIn case you want to keep all rows from the left data frame (data_image) and only add values from data_study where a matching key is available, you can use how=\"left\".","metadata":{}},{"cell_type":"code","source":"# saving data_frame: check output /kaggle/working/slim folder \ntrain.to_csv('/kaggle/working/train_data.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T01:40:42.794506Z","iopub.execute_input":"2021-07-21T01:40:42.794894Z","iopub.status.idle":"2021-07-21T01:40:42.894508Z","shell.execute_reply.started":"2021-07-21T01:40:42.794853Z","shell.execute_reply":"2021-07-21T01:40:42.893545Z"},"trusted":true},"execution_count":null,"outputs":[]}]}